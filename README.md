# CardioCDSS: RAG-based Clinical Decision Support System

## ğŸ©º Overview

**CardioCDSS** is a Retrieval-Augmented Generation (RAG) clinical decision support engine that transforms static cardiovascular guidelines into a structured, queryable medical knowledge system. By combining semantic search, knowledge graph retrieval, and evidence-constrained generation, it delivers patient-specific recommendations grounded strictly in authoritative guidelines.

The project addresses critical barriers in clinical practice: **Guideline Overload** and **Lack of Guideline Awareness**.

## ğŸš€ Key Features

**Hybrid Recall Engine:** Dual-stream retrieval using **ChromaDB** (semantic similarity) and **Neo4j Knowledge Graph** (relational clinical links).

**Multi-Query Expansion:** Automatically generates medical variants of a query to ensure that different clinical terminologies (e.g., "MI" vs. "Myocardial Infarction") all trigger relevant results.

**Context-Aware Reranking:** Filters hundreds of potential guideline chunks down to the top 5 most clinically relevant snippets using cross-attention.

**Modular Architecture:** Strict separation of Query Rewriting, Retrieval, and Generation logic for high maintainability.

**Clinical Guardrails:** Abstention mechanism to prevent hallucinations when guidelines do not cover a specific patient scenario.

---

## ğŸ›¡ï¸ Safety & Transparency

* **Citations:** Every recommendation is accompanied by explicit citations to source guidelines.
* **Human-in-the-loop:** The system is designed for decision support, not autonomous decision-making.

---

## ğŸ› ï¸ Technical Implementation

The system follows a 5-layer clinical RAG pipeline:

1. **Ingestion Layer**  
   Standardized guideline PDFs are parsed, cleaned, and split into overlapping chunks to preserve medical context.

2. **Knowledge Structuring Layer**  
   Subjectâ€“Predicateâ€“Object triplets are extracted (e.g., *Drug â†’ Contraindicated in â†’ Condition*) and stored in a Neo4j knowledge graph to model clinical relationships.

3. **Hybrid Retrieval Layer**  
   - **Vector Search (ChromaDB):** Finds semantically similar guideline text  
   - **Graph Search (Neo4j):** Expands to clinically related concepts  

4. **Context-Aware Reranking Layer**  
   Retrieved candidates are scored against the patient summary (age, BP, LDL-C, comorbidities) using a cross-attention reranker to select the most clinically relevant evidence.

5. **Evidence-Constrained Generation Layer**  
   A guardrailed LLM synthesizes recommendations strictly from retrieved evidence and includes citations. If evidence is insufficient, the system abstains.

---

## âš–ï¸ Framework Tradeoffs & Choices

| Component | Choice | Reason for Choice |
| --- | --- | --- |
| **Vector Store** | **ChromaDB** | Lightweight, persistent, and supports the metadata filtering required for guideline recency (publication year). |
| **Graph DB** | **Neo4j** | Industry standard for representing complex relationships (e.g., Drug A â†’ interacts with â†’ Condition B). |
| **Reranker** | **Cohere v3.0** | Specifically trained for "long-context" document relevance, outperforming standard cosine similarity for dense medical text. |
| **Extraction Model** | **sciphi/triplex** | Pre-trained specifically for (s, p, o) triplet extraction. Much higher graph accuracy than general models. |
| **Hosting Engine** | **Ollama** | Local model hosting reduces data exposure and improves privacy control and No API cost |
| **Graph Logic** | **Graphiti** | Automates the complex "Temporal Graph" logic. Handles node deduplication (knowing "HBP" and "Hypertension" are the same). |
| **Embedder** | **nomic-embed-text** | 8k context window and high performance on medical benchmarks. |
| **Memory** | **Stateless (None)** | Intentionally omitted to prioritize clinical safety and data integrity(see below)


---


**âš ï¸ The Decision for Statelessness (No Memory)**

While conversational memory (Chat History) is common in RAG systems, CardioCDSS is designed as a **Stateless** tool to mitigate high-risk medical errors:

**- Preventing Context Pollution:** Memory poses a risk where data from "Patient A" might persist in the buffer when a clinician begins a query for "Patient B," leading to hallucinated, mixed-patient treatment plans.

**- Mitigating Guideline Drift:** Long-form conversations often cause LLMs to "drift" from their system instructions. Omitting memory ensures the model strictly adheres to the provided guideline context for every single query without the noise of previous exchanges.

**- Clinical Data Integrity:** Every recommendation is generated based solely on the current patient summary and retrieved evidence, ensuring a clean audit trail for every clinical decision.

---

## ğŸ” How This Differs from Standard RAG

| Standard RAG | CardioCDSS |
|-------------|------------|
| Text similarity only | Vector + Knowledge Graph retrieval |
| Free-form generation | Evidence-constrained output |
| Conversational memory | Stateless for clinical safety |


---

## ğŸ“‚ Project Structure

```text
config/
â”œâ”€â”€ config.yaml         # Global settings (Model names, chunk sizes, DB URIs)
â”œâ”€â”€ prompts.yaml        # Centralized YAML for version-controlling LLM instructions
data/
â”œâ”€â”€ guidelines/         # Input directory for authoritative ESC/ACC PDF guidelines
â”œâ”€â”€ patient_cases/      # JSON/CSV repository of structured patient summaries
prompts/
â”œâ”€â”€ recommendation.txt   # Prompt for clinical synthesis & strength of recommendation
â”œâ”€â”€ system_cdss.txt      # Core system identity and medical safety guardrails
src/
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ loader.py        # PDF processing, chunking, and dual-DB ingestion
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ rewriter.py      # Multi-query variant generation (Recall booster)
â”‚   â”œâ”€â”€ generator.py     # LCEL chain logic for guideline-based response synthesis
â”‚   â””â”€â”€ pipeline.py      # The Orchestrator (Coordinates the Hybrid RAG flow)
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ manager.py       # Local Graphiti client & Ollama (Triplex) configuration
â”œâ”€â”€ retrieval/
â”‚   â””â”€â”€ retriever.py     # Singleton manager for ChromaDB and BM25
â””â”€â”€ utils/
â”‚    â”œâ”€â”€ logger.py        # Centralized logging with trace decorators
â”‚    â””â”€â”€ config_loader.py # Configuration and prompt management
tests/
â”‚    â”œâ”€â”€ test_generator.py      # Unit tests for clinical response faithfulness 
â”‚    â”œâ”€â”€ test_loader.py         # Validation for PDF chunking and metadata enrichment
â”‚    â”œâ”€â”€ test_rag_pipeline.py   # End-to-end integration tests for the Hybrid RAG flow
â”‚    â””â”€â”€ test_rewriter.py       # Evaluation for query expansion and medical terminology
â”œâ”€â”€ vectorstore/
â”œâ”€â”€ .env.example
â”œâ”€â”€ app.py                # Streamlit web interface for clinical consultation
â”œâ”€â”€ main.py               # Command-line interface for developer testing
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt

```
---

## ğŸ“¥ Installation & Setup

### 0. Prerequisites



### 1. Clone the Repository
Clone the project repository to your local machine.

```bash
git clone https://github.com/anaboset/cardio-rag-cdss
cd cardio-rag-cdss
```

### 2. Environment & Dependency Management

Using **Conda** or **venv** is recommended to isolate medical libraries.

**Windows:**

```powershell
python -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt

```

**Linux / Mac:**

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

```

### 3. Configuration (.env)

Create a `.env` file in the root directory:

```text
GROQ_API_KEY=your_key_here (or your choice of model)
COHERE_API_KEY=your_key_here
neo4j_uri=bolt://localhost:7687
neo4j_username=neo4j
neo4j_password=your_password

```
---

## ğŸ“– Step-by-Step Usage Guide

You can run and use the app in two ways:

- Command line interface

- Streamlit UI

### Data Preparation
Before running either interface, you must have your medical evidence ready:

Action: Download clinical guidelines (PDF format).

    Note: Use authoritative documents for the best results (e.g., ESC 2025 Guidelines).

Need Guidelines? You can find authoritative documents here:

[American College of Cardiology (ACC)](https://www.acc.org/Guidelines)

[European Society of Cardiology (ESC)](https://www.escardio.org/Guidelines)

[World Health Organization (WHO)](https://www.who.int/southeastasia/activities/management-of-cardiovascular-disease)

### Option A: User-Friendly Web Interface (Streamlit)
Best for a visual, button-click experience.

**Launch the App:** Open your terminal and run:

```Bash
streamlit run app.py
```
**Upload Documents:** Use the Upload button on the sidebar to select your guideline PDFs.

**Process Knowledge:** Click the "Run Ingestion Pipeline" button. Wait for the success message (this builds your Knowledge Graph and Vector Store).

**Consult:** Once complete, enter the Patient Summary and your Clinical Question in the chat box to get a recommendation.

### Option B: Interactive Command Line (CLI)
Best for fast, text-based interaction.

    Place your clinical guidelines in the data/guidelines folder.

**Ingest Data:** Process your guidelines into the system by running:

```Bash
python -m src.ingestion.loader
```
(You will see a progress bar as the AI "reads" your PDFs).

**Start the Assistant:** Launch the interactive chat:

```Bash
python main.py
```
Follow the Prompts: The system will ask you to:

ğŸ‘¤ Enter Patient Summary (e.g., "65yo Male, Smoker, BP 155/95")

ğŸ” Enter your Clinical Question (e.g., "What is the first-line treatment?")

---

## ğŸ§© System Scope

CardioCDSS provides evidence retrieval and synthesis only.  
It does not:

- Interpret imaging
- Access real EHR systems
- Make autonomous treatment decisions

---

## âš ï¸ Known Limitations

- Performance depends on quality and recency of guidelines ingested
- Does not resolve conflicting guideline recommendations
- Cannot reason beyond retrieved evidence

---

## ğŸ§ª Evaluation Plan

CardioCDSS is evaluated as a **clinical decision support system**, not a chatbot.  
Evaluation focuses on evidence alignment, retrieval performance, and safety behavior.

### 1ï¸âƒ£ Retrieval Performance
Measures whether the correct guideline evidence is found.

- **Recall@K** â€” Probability that the relevant guideline section appears in top-K retrieved chunks  
- **Graph Contribution Analysis** â€” % of successful retrievals that relied on knowledge graph expansion

### 2ï¸âƒ£ Generation Faithfulness
Ensures outputs do not contradict retrieved evidence.

- **Faithfulness Score (RAGAS or LLM-based evaluation)**  
- **Contradiction Rate** â€” Frequency of statements unsupported by citations

### 3ï¸âƒ£ Citation Accuracy
Verifies that cited guideline sources actually contain the referenced recommendations.

- Manual clinical review  
- Automated citation-to-source matching

### 4ï¸âƒ£ Safety & Abstention Behavior
Tests system response when guidelines do not contain relevant evidence.

- **Abstention Accuracy** â€” Correctly saying â€œNo relevant guideline foundâ€  
- **Hallucination Rate** â€” Generating unsupported medical advice

### 5ï¸âƒ£ Latency
Clinical usability requires near-real-time performance.

- Target: **< 5 seconds** from query to response


---

## ğŸ“ˆ Success Metrics

To validate the system as a reliable CDSS:

1. **Faithfulness:** Does the answer contradict the retrieved guidelines?

2. **Citation Accuracy:** Are the sources cited (e.g., "ESC 2024") actually the ones containing the data?

3. **Recall @ K:** Does the multi-query retrieval successfully find the correct guideline 95% of the time?

---

## âš ï¸ Medical Disclaimer

This software is intended for **research and decision-support purposes only**.
It is **not a medical device** and **not intended for diagnosis, treatment, or
clinical decision-making without qualified human oversight**.

All clinical decisions must be made by licensed healthcare professionals.
The authors assume no liability for clinical use of this system.

## ğŸ“œ License

Please see [LICENSE](LICENSE) for more information.

---
